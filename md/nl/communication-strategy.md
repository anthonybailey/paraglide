

---
title: Communicatiestrategie
description: Hoe wij communiceren over het pauzeren van AI-ontwikkeling.
---
## Hoe wij communiceren {#how-we-communicate}

- **Verwijs naar experts**. Wij waarschuwen mensen voor een scenario dat zo extreem en angstaanjagend is, dat een instinctieve reactie is om het af te doen als onzin. Toon de [expertpolls en enquêtes](/polls-and-surveys). De [drie meest geciteerde](https://twitter.com/PauseAI/status/1734641804245455017) AI-wetenschappers waarschuwen allemaal voor x-risico's. Het is een goede manier om ons standpunt te onderbouwen door naar hen te verwijzen.
- **Gebruik heldere taal**. Je kunt laten zien dat je de technologie begrijpt en je huiswerk hebt gedaan, maar overmatig jargon kan mensen doen afhaken. Wij willen zoveel mogelijk mensen bereiken, dus gebruik eenvoudige en duidelijke taal. Veel van de mensen die wij willen bereiken zijn niet-moedertaalsprekers van het Engels, dus overweeg vertalingen te maken.
- **Laat onze emoties zien**. Het zien van emoties geeft anderen toestemming om emoties te voelen. Wij zijn bezorgd, wij zijn boos, wij zijn enthousiast om in actie te komen. Het laten zien van hoe je je voelt kan kwetsbaar zijn, maar in ons geval is het noodzakelijk. Onze boodschap kan alleen worden ontvangen als deze overeenkomt met hoe wij hem overbrengen.
- **Benadruk onzekerheid**. Zeg niet dat AI _zal_ de overhand nemen, of dat wij _zullen_ AGI bereiken in x jaar. Niemand kan de toekomst voorspellen. Er is een significante _kans_ dat AI binnenkort verkeerd zal gaan, en dat zou genoeg moeten zijn om in actie te komen. Laat onzekerheid geen reden zijn om niet in actie te komen. Verwijs naar het _voorzorgsprincipe_ en maak het punt dat wij aan de veilige kant moeten blijven.
- **Maak individuen zich verantwoordelijk voelen**. Niemand wil zich verantwoordelijk voelen voor het goed doen gaan van dingen. Onze hersenen sturen ons weg van deze verantwoordelijkheid, omdat wij allemaal een diepe wens hebben om te geloven dat iemand de leiding heeft en ons beschermt. Maar er zijn geen volwassenen in de kamer op dit moment. Jij moet degene zijn die dit doet. Kies ervoor om verantwoordelijkheid te nemen.
- **Inspireer hoop**. Wanneer wij horen over de gevaren van AI en de huidige race naar de bodem, zullen velen van ons een gevoel van wanhoop krijgen, en dat maakt ons passief. Fatalisme is comfortabel, omdat een gebrek aan hoop betekent dat wij niet hoeven te werken aan een goed resultaat. Dit is waarom wij moeten benadrukken dat onze zaak niet verloren is. AGI is [niet onvermijdelijk](/feasibility), technologie is in het verleden met succes internationaal verboden, en ons voorstel heeft brede steun van het publiek.

## Niet doen {#no-gos}

- **Geen AI-gegenereerde visuals**. Het gebruik van AI-modellen is prima voor onderzoek, ideeënvorming en het itereren van ideeën, maar publiceer geen AI-gegenereerde afbeeldingen en video's. Zelfs als wij niet anti-AI zijn, kunnen wij gemakkelijk worden bestempeld als hypocrieten als wij duidelijk AI-gegenereerde content gebruiken.
- **Geen partijpolitiek**. Wij pushen niet voor een politieke partij of ideologie. Wij hebben geen mening over zaken buiten AI.
- **Geen tactische zelfcensuur**. Sommige AI-governanceorganisaties kiezen ervoor om niet te zeggen hoe bezorgd zij zijn, of kiezen ervoor om niet te pushen voor de beleidsmaatregelen die zij nodig achten _omdat zij bang zijn om geloofwaardigheid te verliezen_. Wij kunnen deze strategie niet kopiëren, omdat als wij dat allemaal doen, niemand overblijft om de waarheid te spreken.
- **Geen geruchten**. Wij promoten geen vage of ongeverifieerde informatie. Wij kunnen ons geen geloofwaardigheid veroorloven te verliezen door valse informatie te verspreiden.

## Verhalen die wij pushen {#narratives-that-we-push}

- **AI is niet alleen een gereedschap**. AI-modellen zijn niet geprogrammeerd, zij zijn [digitale hersenen](/digital-brains). Wij begrijpen niet hoe zij werken, wij kunnen niet voorspellen wat zij kunnen doen, wij kunnen hun gedrag niet goed controleren.
- **AI hoeft niet bewust te zijn om gevaarlijk te zijn**. Het vermogen om de wereld te ervaren of emoties te voelen is geen vereiste voor AI om gevaarlijke acties te ondernemen. Het enige dat telt is [mogelijkheden](/dangerous-capabilities).
- **Wereldwijde race naar de bodem**. Dit is geen race om te winnen. Het gaat niet om de VS versus China, het gaat om de mensheid versus AI. Wij kunnen niet verwachten superintelligente AI als wapen te gebruiken - wij weten niet of het überhaupt kan worden gecontroleerd.
- **Bestaande AI-schade zal erger worden**. Deepfakes, baanverlies, surveillance, desinformatie, polarisatie... Bestaande AI veroorzaakt al schade en wij moeten dat erkennen. De schade zal alleen maar erger worden met krachtigere AI, en wij moeten AI pauzeren om dat te voorkomen.
- **Supermenselijke AI is niet onvermijdelijk**. Het vereist hordes ingenieurs met miljoenen dollars aan salaris. Het vereist zeer gespecialiseerde hardware, gecreëerd door een handvol monopolies. Het vereist dat wij allemaal niets doen.
- **Internationale regulering is mogelijk**. Wij hebben collectief de ozonlaag beschermd door CFC's en verblindende laserwapens wereldwijd te verbieden. De gecentraliseerde AI-chipketen maakt het afdwingen van rekenkrachtgovernance zeer [haalbaar](/feasibility).

Veel van onze strategie is afgeleid van onze [waarden](https://pauseai.info/values).