

---
title: Fähigkeiten moderner KI-Systeme im Vergleich zum Menschen
description: Wie intelligent sind die neuesten KI-Modelle im Vergleich zum Menschen?
---
Wie intelligent sind die neuesten KI-Modelle im Vergleich zum Menschen?
Lassen Sie uns einen Blick darauf werfen, wie die leistungsfähigsten KI-Systeme im Vergleich zum Menschen in verschiedenen Bereichen abschneiden.
Die Liste unten wird regelmäßig aktualisiert, um die neuesten Entwicklungen widerzuspiegeln.

_Letzte Aktualisierung: 2024-09-16_

## Übermenschlich (Besser als alle Menschen) {#superhuman-better-than-all-humans-1}

- **Spiele**: Bei vielen Spielen ([Schach, Go](https://de.wikipedia.org/wiki/AlphaGo_Zero), Starcraft, Dota, [Gran Turismo](https://www.technologyreview.com/2022/07/19/1056176/sonys-racing-ai-destroyed-its-human-competitors-by-being-nice-and-fast/) usw.) ist die beste KI besser als der beste Mensch.
- **Arbeitsgedächtnis**: Ein durchschnittlicher Mensch kann etwa 7 Elemente (wie Zahlen) gleichzeitig merken. Gemini 1.5 Pro [kann 99 % von 7 Millionen Wörtern lesen und merken](https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/#sundar-note).
- **Lesegeschwindigkeit**: Ein Modell wie Gemini 1.5 Pro kann ein ganzes Buch in 30 Sekunden lesen. Es kann eine völlig neue Sprache lernen und Texte in einer halben Minute übersetzen.
- **Schreibgeschwindigkeit**: KI-Modelle können mit Geschwindigkeiten schreiben, die weit über denen eines Menschen liegen, und ganze Computerprogramme in Sekunden schreiben.
- **Wissensumfang**: Moderne LLMs wissen weit mehr als jeder Mensch, ihr Wissen umfasst praktisch jeden Bereich. Es gibt keinen Menschen, dessen Wissensbreite auch nur annähernd kommt.

## Besser als die meisten Menschen {#better-than-most-humans-1}

- **Programmierung**: o3 schlägt [99,9 % der menschlichen Programmierer](https://arxiv.org/abs/2502.06807) im sehr anspruchsvollen Codeforces-Wettbewerb. Es schafft es, 71,7 % der Programmierprobleme im SWE-Benchmark zu lösen, was zeigt, dass es auch reale Software-Engineering-Probleme sehr effektiv lösen kann.
- **Schreiben**: Im Dezember 2023 gewann ein von einer KI geschriebener Roman einen Preis bei einem [nationalen Science-Fiction-Wettbewerb](https://www.scmp.com/news/china/science/article/3245725/chinese-professor-used-ai-write-science-fiction-novel-then-it-won-national-award?campaign=3245725&module=perpetual_scroll_0&pgtype=article). Der Professor, der die KI verwendete, erstellte die Erzählung aus einem Entwurf von 43.000 Zeichen, der in nur drei Stunden mit 66 Eingaben generiert wurde. Die besten Sprachmodelle haben ein übermenschliches Vokabular und können in vielen verschiedenen Stilen schreiben.
- **Übersetzen**: Und sie können auf alle wichtigen Sprachen fließend antworten und übersetzen.
- **Kreativität**: Besser als 99 % der Menschen bei den [Torrance-Tests für kreatives Denken](https://neurosciencenews.com/ai-creativity-23585/), bei denen relevante und nützliche Ideen generiert werden müssen. Allerdings waren die Tests relativ klein und für größere Projekte (z. B. die Gründung eines neuen Unternehmens) ist die KI noch nicht autonom genug.
- **Fachwissen**: o3 [antwortet korrekt auf 87,7 %](https://openai.com/index/learning-to-reason-with-llms/) der GPQA-Diamantenfragen und übertrifft damit menschliche Fachexperten (PhDs), die nur 69,7 % erreichen.
- **Visuelles Denken**: o3 erreichte eine Punktzahl von [87,5 % im ARC-AGI-Benchmark](https://arcprize.org/blog/oai-o3-pub-breakthrough) (menschlicher Durchschnitt: 60 %), der speziell dafür entwickelt wurde, um für große Sprachmodelle schwierig zu sein.
- **Mathematik**: o3 gehört zu den besten 500 Schülern in den USA in einem Qualifikationstest für die USA-Mathematik-Olympiade (AIME).
- **Überzeugungskraft**: GPT-4 konnte mit Zugang zu persönlichen Informationen die Zustimmung der Teilnehmer zu den Argumenten ihrer Gegner um bemerkenswerte [81,7 Prozent](https://arxiv.org/abs/2403.14380) erhöhen, verglichen mit Debatten zwischen Menschen – fast doppelt so überzeugend wie die menschlichen Debattierer.
- **Intelligenztests**: Bei verbalen Intelligenztests haben LLMs seit einiger Zeit 95 bis 99 % der Menschen übertroffen (Punktzahl zwischen [125](https://medium.com/@soltrinox/the-i-q-of-gpt4-is-124-approx-2a29b7e5821e) und [155](https://www.scientificamerican.com/article/i-gave-chatgpt-an-iq-test-heres-what-i-discovered/)). Bei non-verbalen (Mustererkennungs-)Intelligenztests erreichte das 2024 o1-preview-Modell [120 Punkte im Mensa-Test](https://www.maximumtruth.org/p/massive-breakthrough-in-ai-intelligence), womit es 91 % der Menschen übertraf.
- **Spezialwissen**: GPT-4 erreicht 75 % im [Medical Knowledge Self-Assessment Program](https://openai.com/research/gpt-4), Menschen im Durchschnitt zwischen [65 und 75 %](https://pubmed.ncbi.nlm.nih.gov/420438/). Es schneidet besser ab als [68](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4441311) bis [90 %](https://law.stanford.edu/2023/04/19/gpt-4-passes-the-bar-exam-what-that-means-for-artificial-intelligence-tools-in-the-legal-industry/) der Jurastudenten bei der Anwaltsprüfung.
- **Kunst**: Bildgenerierungsmodelle haben [Kunst-](https://dataconomy.com/2022/09/26/ai-artwork-wins-art-competition) und sogar [Fotowettbewerbe](https://www.artnews.com/art-news/news/ai-generated-image-world-photography-organization-contest-artist-declines-award-1234664549) gewonnen.
- **Forschung**: GPT-4 kann [autonome chemische Forschung](https://www.nature.com/articles/s41586-023-06792-0) betreiben und DeepMind hat eine KI entwickelt, die [eine Lösung für ein offenes mathematisches Problem gefunden hat](https://www.nature.com/articles/s41586-023-06924-6). Allerdings erfordern diese Architekturen viel menschliches Engineering und sind nicht allgemein einsetzbar.
- **Hacking**: GPT-4 kann [autonom Websites hacken](https://arxiv.org/html/2402.06664v1) und [schlägt 89 % der Hacker](https://arxiv.org/pdf/2402.11814.pdf) in einem Capture-the-Flag-Wettbewerb.

## Schlechter als die meisten Menschen {#worse-than-most-humans-1}

- **"Ich weiß nicht" sagen**. Praktisch alle großen Sprachmodelle haben dieses Problem der "Halluzination", also das Erfinden von Informationen, anstatt zu sagen, dass sie es nicht wissen. Dies mag wie ein relativ kleiner Mangel erscheinen, aber es ist ein sehr wichtiger. Es macht LLMs unzuverlässig und limitiert ihre Anwendbarkeit stark. Allerdings zeigen Studien, dass größere Modelle weit weniger halluzinieren als kleinere.
- **Ein überzeugender Mensch sein**. GPT-4 kann [54 % der Menschen davon überzeugen](https://arxiv.org/abs/2405.08007), dass es ein Mensch ist, aber Menschen können dies 67 % der Zeit tun. Mit anderen Worten, GPT-4 besteht den Turing-Test noch nicht konsequent.
- **Geschickte Bewegung**. Kein Roboter kann sich wie ein Mensch bewegen, aber wir kommen näher. Der [Atlas-Roboter kann gehen, Objekte werfen und Saltos machen](https://www.youtube.com/watch?v=-e1_QhJ1EhQ). Googles [RT-2](https://www.deepmind.com/blog/rt-2-new-model-translates-vision-and-language-into-action) kann Ziele in der realen Welt in Aktionen umsetzen, wie "den Becher zum Weinflasche bewegen". Teslas Optimus-Roboter kann [Kleidung falten](https://electrek.co/2024/01/15/tesla-optimus-robot-cant-build-cars-folding-clothes/) und der bipede Roboter von Figure kann [Kaffee machen](https://www.youtube.com/watch?v=Q5MKo7Idsok).
- **Selbstreplikation**. Alle Lebewesen auf der Erde können sich selbst replizieren. KI-Modelle könnten sich von Computer zu Computer durch das Internet verbreiten, aber dies erfordert eine Reihe von Fähigkeiten, die KI-Modelle noch nicht besitzen. Eine Studie aus dem Jahr 2023 listet eine Reihe von 12 Aufgaben für die Selbstreplikation auf, von denen getestete Modelle 4 erfüllten. Im Dezember 2024 zeigte eine Studie, dass verschiedene Open-Source-Modelle sich auf einem Computer selbst replizieren können, wenn sie entsprechendes Werkzeug erhalten. Eine KI, die erfolgreich selbst repliziert, könnte zu einer KI-Übernahme führen.
- **Kontinuierliches Lernen**. Aktuelle SOTA-LLMs trennen Lernen ("Training") von Tun ("Inferenz"). Obwohl LLMs mithilfe ihres Kontexts lernen können, können sie ihre Gewichte nicht aktualisieren, während sie verwendet werden. Menschen lernen und tun gleichzeitig. Es gibt jedoch mehrere mögliche Ansätze für kontinuierliches Lernen. Eine Studie aus dem Jahr 2024 beschrieb einige aktuelle Ansätze für kontinuierliches Lernen in LLMs.
- **Ziele erreichen**, für die sie nicht trainiert wurden und die nicht darin bestehen, Text, Bilder oder Audio auszugeben. Wenn Sie ein LLM mit Kontrolle über einen Computer oder einen Roboter auffordern, nicht-super-einfache Aktionen auszuführen oder Ziele in virtuellen oder realen Umgebungen zu erreichen, die weit von seiner Trainingsverteilung entfernt sind, wird es wahrscheinlich scheitern.
- **Planung**. LLMs sind noch nicht sehr gut bei der Planung (z. B. beim Nachdenken darüber, wie man Blöcke auf einem Tisch stapelt). Allerdings performen größere Modelle wesentlich besser als kleinere.

## Der Endpunkt {#the-endpoint-1}

Mit fortschreitender Zeit und verbesserten Fähigkeiten verschieben wir Elemente von den unteren Abschnitten in den oberen Abschnitt.
Wenn bestimmte gefährliche Fähigkeiten erreicht werden, wird die KI neue Risiken darstellen.
Irgendwann wird die KI jeden Menschen in jeder vorstellbaren Metrik überbieten.
Wenn wir diese Superintelligenz geschaffen haben, werden wir wahrscheinlich bald tot sein.
Lasst uns eine Pause implementieren, um sicherzustellen, dass wir nicht dorthin kommen.